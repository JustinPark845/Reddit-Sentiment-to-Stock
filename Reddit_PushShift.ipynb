{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustinPark845/Natural-Language-Processing-Final-Project/blob/main/Reddit_PushShift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VHwySKSuVfwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTT4cUHQbDL_"
      },
      "outputs": [],
      "source": [
        "! pip install psaw        \n",
        "\n",
        "from psaw import PushshiftAPI    #library Pushshift\n",
        "import datetime as dt            #library for date management\n",
        "\n",
        "api = PushshiftAPI()              #Object of the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LbxpWTew52h"
      },
      "outputs": [],
      "source": [
        "def create_dataset(start_date,stop_date,end_date,score,limit):\n",
        "  res = {}\n",
        "# Amazon Apple Microsoft Google Telsa\n",
        "  term = \"AMZN|AAPL|MSFT|GOOGL|TSLA|NVDA|AMD|NFLX|SPY|META\"\n",
        "  subreddit = \"wallstreetbets\"\n",
        "  sort = \"desc\"\n",
        "  sort_type = \"score\"\n",
        "\n",
        "  delta=dt.timedelta(days=1)\n",
        "\n",
        "  while (start_date <= end_date):\n",
        "    # Debug Statement\n",
        "    print(start_date, end=\"\\n\")\n",
        "    post_list = []\n",
        "    posts = list(api.search_submissions(\n",
        "        q=term,                #term we want to audit\n",
        "        subreddit = subreddit, #Subreddit we want to audit\n",
        "        sort=sort,             #Sort asc or desc\n",
        "        sort_type=sort_type,   #Sort type (score)\n",
        "        after=start_date,      #Start date\n",
        "        before=stop_date,      #End date\n",
        "        score=score,           #Score threshold\n",
        "        limit=limit,\n",
        "        ))\n",
        "    for post in posts:\n",
        "        post_entry = (post.d_[\"title\"],post.d_[\"title\"] + post.d_.get(\"selftext\", \"\"))\n",
        "        post_list.append(post_entry)\n",
        "    res[str(start_date)] = post_list\n",
        "    start_date += delta\n",
        "    stop_date += delta\n",
        "\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TXKNICKbOzN"
      },
      "outputs": [],
      "source": [
        "# 2018\n",
        "start_date = dt.date(2018, 1, 1)\n",
        "stop_date = dt.date(2018,1,2)\n",
        "end_date = dt.date(2018, 12, 31)\n",
        "res_2018 = create_dataset(start_date, stop_date, end_date,\">4\",1000)\n",
        "\n",
        "f=open(\"/content/drive/MyDrive/nlp_project/5thres_res_2018.txt\", \"w\")\n",
        "f.write(str(res_2018))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2019\n",
        "start_date = dt.date(2019, 1, 1)\n",
        "stop_date = dt.date(2019,1,2)\n",
        "end_date = dt.date(2019, 12, 31)\n",
        "res_2019 = create_dataset(start_date, stop_date, end_date,\">4\",1000)\n",
        "\n",
        "f=open(\"/content/drive/MyDrive/nlp_project/5thres_res_2019.txt\", \"w\")\n",
        "f.write(str(res_2019))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Co39rTE3LZcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021\n",
        "start_date = dt.date(2021, 1, 1)\n",
        "stop_date = dt.date(2021,1,2)\n",
        "end_date = dt.date(2021, 12, 31)\n",
        "res_2021 = create_dataset(start_date, stop_date, end_date,\">4\",1000)\n",
        "\n",
        "f=open(\"/content/drive/MyDrive/nlp_project/5thres_res_2021.txt\", \"w\")\n",
        "f.write(str(res_2021))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "NVaRNKW3d0Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2022\n",
        "start_date = dt.date(2022, 1, 1)\n",
        "stop_date = dt.date(2022,1,2)\n",
        "end_date = dt.date.today()\n",
        "res_2022 = create_dataset(start_date, stop_date, end_date,\"\",10)\n",
        "\n",
        "f=open(\"/content/drive/MyDrive/nlp_project/10lim_res_2022.txt\", \"w\")\n",
        "f.write(str(res_2022))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "6aEWxLDghM00"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}